


AI Alignment - Research Engineer







CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsPricingDevelopersOverviewDocumentationAPI referenceExamplesSafetyCompanyAboutBlogCareersCharterSecuritySearch Navigation quick links Log inSign upMenu Mobile Navigation CloseSite NavigationResearchProductDevelopersSafetyCompany Quick Links Log inSign upSearch Submit AI Alignment - Research EngineerSan Francisco, California, United States â AlignmentApply nowAI Alignment Team - Research EngineerÂ The OpenAI Alignment Team is working on technical approaches to ensure that artificial general intelligence (AGI) aligns with human values and follows human intent. Through scientific experimentation, we explore the scalability of alignment techniques and identify potential breaking points.Our approach to alignment research primarily focuses on engineering a scalable training signal for advanced AI systems that aligns with human intent. This approach is built upon three main pillars:Training AI systems using human feedback, such as learning from human instructionsTraining AI systems to assist human evaluation, such as training models to self-critiqueTraining AI systems to conduct alignment research, such as using language models to explain neurons in language modelsAbout the RoleWe are seeking research engineers and research scientists to help design and implement experiments for alignment research. Responsibilities may include:Designing experiments to measure the effectiveness of scalable oversight techniques such as AI-assisted feedback and DebateStudying generalization to see when AI systems trained on easy problem can solve hard problemsManaging large datasets from interpretability experiments and creating visualizations to explore interpretability dataDeveloping experiments to test how well chain of thought reasoning reflects model cognitionInvestigating situations when training against a reward signal causes model outputs to deteriorateExploring methods to understand and predict model behaviors, such as finding inputs causing anomalous circuits or catastrophic outputsDesigning novel approaches for using LLMs in alignment researchYou might thrive in this role if you:Are excited about OpenAI's missionPossess a strong curiosity about aligning and understanding ML models, and are motivated to use your career to address this challengeEnjoy fast-paced, collaborative, and cutting-edge research environmentsHave experience implementing ML algorithms (e.g., PyTorch)Can develop data visualization or data collection interfaces (e.g., JavaScript, Python)Want to ensure that powerful AI systems stay under human controlAbout OpenAIOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.Â At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.Compensation, Benefits and PerksThe annual salary range for this role is $200,000 â $370,000. Total compensation also includes generous equity and benefits:Â Medical, dental, and vision insurance for you and your familyMental health and wellness support401(k) plan with 4% matchingUnlimited time off and 18+ company holidays per yearPaid parental leave (20 weeks) and family-planning supportAnnual learning & development stipend ($1,500 per year)We are an equal opportunity employer and do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, veteran status, disability or any other legally protected status. Pursuant to the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records.Â We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via thisÂ link.OpenAI US Applicant Privacy PolicyApply nowResearchOverviewIndexProductOverviewChatGPTGPT-4DALLÂ·E 2Customer storiesSafety standardsPricingSafetyOverviewCompanyAboutBlogCareersCharterSecurityOpenAI Â© 2015âââ2023Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
